{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "script_gridduck.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asleybach/googlecolab-notebooks/blob/main/script_gridduck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYVpDUcizxH"
      },
      "source": [
        "# Script Gridduck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEgL2Ds-8_Mc",
        "outputId": "df7259f0-7224-4776-a87c-e462f286704e"
      },
      "source": [
        "pip install psycopg2-binary"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.6/dist-packages (2.8.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qErPAVxUizyG"
      },
      "source": [
        "import calendar\n",
        "import json\n",
        "import os\n",
        "\n",
        "from datetime import datetime, timedelta, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "from time import gmtime, strftime\n",
        "# from data_acquisition_API import GridDuck, process_readings_to_values\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy.sql.expression import update\n",
        "# from connectionDb import (\n",
        "#    DATABASE_CONNECTION, ConsumptionResources,\n",
        "#    Metadata\n",
        "#)\n",
        "from sqlalchemy import (\n",
        "    create_engine, Column, BigInteger,\n",
        "    String, Boolean, Text, Sequence, MetaData, Table,\n",
        "    DateTime, Numeric\n",
        ")\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from getpass import getpass\n",
        "import requests"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToaCUlPju5LA"
      },
      "source": [
        "# DATA PROCESSING FUNCTIONS\n",
        "def process_readings_to_values( data_readings):\n",
        "  \"\"\" Returns a list of the values, descarts the indexes and timestamps\n",
        "  \"\"\"\n",
        "  values = []\n",
        "  if data_readings:\n",
        "    for dd in data_readings:\n",
        "      values.append(dd[2])\n",
        "  return values"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwpsKrPhH6OA"
      },
      "source": [
        "# Definition of the tables in the consumption database\n",
        "Base = declarative_base()\n",
        "class Metadata(Base):\n",
        "    __tablename__ = 'consumption_metadata'\n",
        "    \n",
        "    id = Column(BigInteger, Sequence('metadata_id_seq'), primary_key=True)\n",
        "    veId = Column(String(254))\n",
        "    ve_name = Column(String(128))\n",
        "    ve_active = Column(Boolean, unique=False)\n",
        "    ve_city = Column(String(128))\n",
        "    ve_contry = Column(String(128))\n",
        "    postalCode = Column(String(128))\n",
        "    resourceId = Column(String(254))\n",
        "    resource_name = Column(String(128))\n",
        "    resource_description = Column(Text)\n",
        "    resource_active = Column(Boolean, unique=False)\n",
        "    resource_classifier = Column(String(128))\n",
        "    baseUnit = Column(String(32))\n",
        "\n",
        "class ConsumptionResources(Base):\n",
        "    __tablename__ = 'consumption_resourceconsumption'\n",
        "\n",
        "    id = Column(BigInteger, Sequence('consumption_resourceconsumption_id_seq'), primary_key=True)\n",
        "    timestamp = Column(DateTime)\n",
        "    consumption = Column(String(254))\n",
        "    reference_resource = Column(String(254))\n",
        "\n",
        "\n",
        "Metadata.__table__.create(bind=DATABASE_CONNECTION, checkfirst=True)\n",
        "ConsumptionResources.__table__.create(bind=DATABASE_CONNECTION, checkfirst=True)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv3SAUhL5FK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47b153e-bfed-4c4c-d1e4-095202b9aed4"
      },
      "source": [
        "# start request session\n",
        "_DATABASE_CONSUMPTION_URL = getpass('Enter db url value: ')\n",
        "DATABASE_CONNECTION = create_engine(_DATABASE_CONSUMPTION_URL)\n",
        "Session = sessionmaker(bind=DATABASE_CONNECTION)\n",
        "Session = sessionmaker()\n",
        "Session.configure(bind=DATABASE_CONNECTION)\n",
        "_session = Session()\n",
        "session = requests.Session()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter db url value: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zu3psWivg7d"
      },
      "source": [
        "# definition of the class corresponding to the interaction with the Gridduck api\n",
        "class GridDuck:\n",
        "  \"\"\" Model for GridDuck API\n",
        "  \"\"\"\n",
        "  def __init__(self, token):\n",
        "    \"\"\"\n",
        "    Creates and checks connection\n",
        "    Args: token\n",
        "\n",
        "    \"\"\"\n",
        "    self.token = token\n",
        "    self.url = URL_GD\n",
        "    # self.resources = []\n",
        "\n",
        "    self._test_connection()\n",
        "\n",
        "    self.resources = self.get_resources_list()\n",
        "    self.resources_metadata = self.get_resources_meta()\n",
        "\n",
        "    self.names = self.get_names()\n",
        "    self.good_resources = []\n",
        "    \n",
        "  def _test_connection(self):\n",
        "    \"\"\"\n",
        "      Prints if connection is successful\n",
        "    \"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {self.token}\"}\n",
        "    url = f\"{self.url}/asset?offset=0&limit=500\"\n",
        "    response = session.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    if not data:\n",
        "      print(\"ERROR - No connection, check API\")\n",
        "    else:\n",
        "      print('API connection ok')\n",
        "      return data\n",
        "    if response.ok:\n",
        "      return response.json()\n",
        "    if response.status_code == 404:\n",
        "      print(f\"Url not found {url} -- Status code: {response.status_code} -- {response.text}\")\n",
        "      return {}\n",
        "      print(f\"Faild to connect to Glowmarkt API - code:{response.status_code}\")\n",
        "      response.raise_for_status()\n",
        "      return {}\n",
        "\n",
        "  def get_names(self):\n",
        "    \"\"\"Returns list of site names\"\"\"\n",
        "    data = self.get_resources_meta()\n",
        "    names = []\n",
        "    for dd in data:\n",
        "      site = dd.get(\"site_name\", 'NO_NAME')\n",
        "      if not site in names:\n",
        "        names.append(site)\n",
        "      names = sorted(names)\n",
        "      return names\n",
        "\n",
        "  def get_resources_by_keyword(self, keyword):\n",
        "    \"\"\"\n",
        "    Returns list of resource id that match a keyword on the site name\n",
        "    \"\"\"\n",
        "    names_matched = []\n",
        "    resources = []\n",
        "\n",
        "    for res in self.resources_metadata:\n",
        "      site_name = res.get(\"site_name\", 'NO_NAME')\n",
        "      if not site_name.find(keyword) == -1:\n",
        "        if not site_name in names_matched: names_matched.append(site_name)\n",
        "        resources.append(res.get(\"id\",\"NO_ID\"))\n",
        "\n",
        "        if resources:\n",
        "          print(f'Found {len(resources)} resources in {len(names_matched)} site/sites')\n",
        "        else:\n",
        "          print(f'Did NOT find any resources or matches for {keyword}')\n",
        "\n",
        "        return resources\n",
        "\n",
        "  def is_data_good(self, values, print_stats = False, return_stats= False):\n",
        "    return _is_data_good(values, print_stats, return_stats)\n",
        "\n",
        "  # GD API SET OF METHODS 1 - GET REOURCES - /asset?offset=0&limit=500\n",
        "\n",
        "  def get_resources_meta(self) -> list:\n",
        "    \"\"\"\n",
        "    Gets list of all resources METADATA\n",
        "    Makes every required query in order to fetchthe complete set\n",
        "    of available assets for the current oauth token.        \n",
        "    Returns:\n",
        "      A list of dictionaries\n",
        "      Previous name: retrieve_all_resources_raw_version\n",
        "    \"\"\"\n",
        "    # Get assest. Beware of pagination\n",
        "    headers = {\"Authorization\": f\"Bearer {self.token}\"}\n",
        "    custom_url = f\"{self.url}/asset?offset=0&limit=500\"\n",
        "    response = session.get(custom_url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    data = response.json()\n",
        "    if not data:\n",
        "      return []\n",
        "\n",
        "    assets = data.get(\"results\")\n",
        "    pagination_urls = data.get(\"links\")\n",
        "\n",
        "    while pagination_urls.get(\"next\") is not None:\n",
        "      try:\n",
        "        custom_url = pagination_urls.get(\"next\")  # python 3.8  <3\n",
        "        more, pagination_urls = self._get_resources_meta(custom_url, headers)\n",
        "        assets.extend(more)\n",
        "      except Exception:\n",
        "        #logger.exception(\"error retrieve all\")\n",
        "        print(\"error retrieve all in pagination\")\n",
        "        break\n",
        "    return assets\n",
        "\n",
        "  def _get_resources_meta(self, custom_url, headers):\n",
        "    \"\"\"Aux function of retrieve_all_resources_raw_version to deal with pagination\n",
        "    \"\"\"\n",
        "    response = session.get(custom_url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    if data.get(\"results\"):\n",
        "      return data[\"results\"], response.get(\"links\")\n",
        "    return [], response.get(\"links\")\n",
        "\n",
        "  def get_resources_list(self) -> list:\n",
        "    \"\"\"\n",
        "    Gets a list of all resources ids\n",
        "    Previous name: retrieve_all_resources\n",
        "    \"\"\"\n",
        "    return [r.get(\"id\") for r in self.get_resources_meta() ]\n",
        "\n",
        "  #  metadata for all resources\n",
        "  def get_resources_meta_summary(self):\n",
        "    \"\"\"\n",
        "      Gets list of resources with metadata\n",
        "      previous name: retrieve_all_resources_metadata_GD\n",
        "    \"\"\"\n",
        "    return [\n",
        "      {\n",
        "        \"id\": r.get(\"id\"),\n",
        "        \"name\": r.get(\"name\").strip(),\n",
        "        \"site_name\": r.get(\"site_name\"),\n",
        "        \"site_id\": r.get(\"site_id\"),\n",
        "        \"code\": r.get(\"code\"),\n",
        "        \"installed_at\": r.get(\"created_stamp\"),\n",
        "        \"status\": r.get(\"status\")\n",
        "      }\n",
        "      for r in self.get_resources_meta()\n",
        "        ]\n",
        "\n",
        "  def get_resource_meta(self, res_id):\n",
        "    \"\"\"\n",
        "      Gets resource meta data, all metadata available\n",
        "    \"\"\"\n",
        "    for resource in self.resources_metadata:\n",
        "      if res_id == resource.get(\"id\"):\n",
        "        return resource\n",
        "    return {}\n",
        "  def get_resource_meta_summary(self, res_id):\n",
        "    \"\"\"\n",
        "      Gets resource meta data, from get_resources_meta_summary so a cleaned version of data\n",
        "    \"\"\"\n",
        "    meta = self.get_resources_meta_summary()\n",
        "    for resource in meta:\n",
        "      if resource.get('id') == res_id:\n",
        "        return resource\n",
        "      return []\n",
        "\n",
        "  '''def get_resource_meta(self, didentifier):\n",
        "    \"\"\"\n",
        "    Returns all the metadata for a specific resource\n",
        "    \"\"\"\n",
        "    #resources = self.get_resources_list()\n",
        "    resources = self.get_resources_meta()\n",
        "    for resource in resources:\n",
        "      if identifier == resource.get(\"id\"):\n",
        "        return resource\n",
        "    return {}'''\n",
        "\n",
        "  def get_resource(self, res_id: str) -> dict:\n",
        "    \"\"\"Retrieves a single asset by id\n",
        "      Calls to the asset\n",
        "    \"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {self.token}\"}\n",
        "    custom_url = f\"{self.url}/asset/{res_id}\"\n",
        "    response = session.get(custom_url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "  # CONSUMPTION READINGS\n",
        "  def _get_readings(self, asset_id: str, timestamp_start, timestamp_end, granularity) -> list:\n",
        "    \"\"\"\n",
        "      # Gets the data given parameters\n",
        "      Previous name: _retrieve_readings_params_GD\n",
        "    \"\"\"\n",
        "    MIN = 60\n",
        "    HOUR = 60 * 60\n",
        "    if granularity == \"min\": granularity = int(MIN * 1) \n",
        "    if granularity == \"1min\": granularity = int(MIN * 1)\n",
        "    if granularity == \"2min\": granularity = int(MIN * 2)\n",
        "    if granularity == \"5min\": granularity = int(MIN * 5)\n",
        "    if granularity == \"10min\": granularity = int(MIN * 10)\n",
        "    if granularity == \"15min\": granularity = int(MIN * 15)\n",
        "    if granularity == \"30min\": granularity = int(MIN * 30)\n",
        "    if granularity == \"H\": granularity = int(HOUR * 1)\n",
        "    if granularity == \"D\": granularity = int(HOUR * 24)\n",
        "    if granularity == \"W\": granularity = int(HOUR * 24 * 7)\n",
        "    if granularity == \"M\": granularity = int(HOUR * 24 * 30)\n",
        "    #if granularity == \"Y\": granularity = \"P1Y\"\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {self.token}\"}\n",
        "    custom_url = (\n",
        "        f\"{self.url}/asset/{asset_id}/consumption/{timestamp_start}\"\n",
        "        f\"/{timestamp_end}/{granularity}\"\n",
        "    )\n",
        "    response = session.get(custom_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 400:\n",
        "        print(f\"Bad request {response.text}\")\n",
        "\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "        \n",
        "    if not data:\n",
        "        return []\n",
        "\n",
        "    readings = []\n",
        "    for rr in data:\n",
        "      readings.append([rr.get('time'),datetime.utcfromtimestamp(rr.get('time')).strftime(\"%Y-%m-%d %H:%M\"), rr.get('consumption')])\n",
        "      \n",
        "    return readings \n",
        "  def get_readings(self, asset_id, start_date, period_days, granularity = 3600)  -> list:\n",
        "    \"\"\"\n",
        "    Gets the data - queries day by day\n",
        "      \n",
        "    start_date -> datetime(2020, 11, 1)\n",
        "    period -> number of days\n",
        "    granularity -> number of seconds\n",
        "    \"\"\"\n",
        "\n",
        "    DAYSEC = 86400\n",
        "    SLEEP_TIME = 0.01\n",
        "\n",
        "    start_date = start_date.strftime('%s')\n",
        "\n",
        "    try:\n",
        "      readings = []\n",
        "      for ii in range(period_days):\n",
        "        starti = int(start_date) + (ii * DAYSEC)\n",
        "        endi = starti + DAYSEC\n",
        "        res = self._get_readings(asset_id, str(starti), str(endi), granularity)\n",
        "        if res:\n",
        "          for rr in res:\n",
        "            readings.append(rr)\n",
        "            time.sleep(SLEEP_TIME)\n",
        "      return readings\n",
        "    except Exception as e:\n",
        "      print(f\"ERROR during resource {asset_id} on day {starti}\")\n",
        "      print(e)\n",
        " \n",
        "  def get_readings_new(self, resid, prints = False):\n",
        "    \"\"\"\n",
        "      For 1 resource id: returns Readings for the prototyping period.\n",
        "      Checks for good data\n",
        "    \"\"\" \n",
        "    timestamp_start = datetime(2020,11,10,0,0).strftime('%s')\n",
        "    timestamp_end = datetime(2020,12,28,0,0).strftime('%s')\n",
        "    granularity = 60*60*24\n",
        "\n",
        "    #START_DATE = datetime(2020, 11, 1)\n",
        "    #PERIOD_DAYS = 32\n",
        "        \n",
        "    data = self._get_readings(resid, timestamp_start, timestamp_end, granularity)\n",
        "        \n",
        "    if data:\n",
        "      values = process_readings_to_values(data)\n",
        "      is_good_data = self.is_data_good(values, prints)\n",
        "      if is_good_data == False:\n",
        "        print(f'-This resource does not have good data-')\n",
        "      return values, data\n",
        "\n",
        "    else:\n",
        "      print(\"Error reading data. Seems empty. Data:\")\n",
        "      print(data)\n",
        "      return None\n",
        "\n",
        "  def save_readings(self, user_res_id, start_date, period_days, granularity = 3600, filename_prefix = \"\", filename_suffix = \"\"):\n",
        "    \"\"\" \n",
        "    Retreives data and saves to a file\n",
        "    start_date format -> datetime(2020, 11, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    if filename_suffix == \"\": filename_suffix = \"_\" + granularity \n",
        "    filename = filename_prefix + user_res_id + filename_suffix + \".csv\"\n",
        "      \n",
        "    readings = self.get_readings(user_res_id, start_date, period_days, granularity)\n",
        "    readings = process_readings_trim_start(readings)\n",
        "    df = pd.DataFrame(readings, columns = ['datetime', 'date', 'data'] )\n",
        "    df = df.set_index('datetime')\n",
        "    #df.to_csv(r\"~/Downloads/\" + user_res_id + FILETYPE)\n",
        "    df.to_csv(filename)\n",
        "    print(f\"File saved: {filename}\")"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbWzPimFizyZ",
        "outputId": "094b4abc-2b13-4ebe-fca5-22f871fe1644"
      },
      "source": [
        "# gridDuck token\n",
        "TOKEN_GD = getpass('Enter gridDuck token: ')\n",
        "URL_GD = \"https://v1.api.gridduck.com\"\n",
        "gd = GridDuck(TOKEN_GD)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter gridDuck token: ··········\n",
            "API connection ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0KSh5ywizy0"
      },
      "source": [
        "## Handling of the data obtained corresponding to the resources\n",
        "all_resources = gd.resources_metadata\n",
        "# variable to control the last 3 months\n",
        "month_period = 3\n",
        "# current date\n",
        "#date_now = datetime.now()\n",
        "now = date.today()\n",
        "date_now = datetime.strptime(now.ctime(), '%c')\n",
        "# start of the date from the control month\n",
        "start_date = date_now - relativedelta(months=month_period)\n",
        "# days of the month\n",
        "period_days = calendar.monthrange(start_date.year, start_date.month)[1] + 1\n",
        "# type of period to obtain consumption data\n",
        "period = 'min'"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAxWfI5OizzA"
      },
      "source": [
        "data_consumption = {\n",
        "    'timestamp': [],\n",
        "    'consumption': [],\n",
        "    'reference_resource': []\n",
        "}\n",
        "\n",
        "data_resources_inactive = {\n",
        "    'veId': [],\n",
        "    've_name': [],\n",
        "    've_active': [],\n",
        "    've_city': [],\n",
        "    've_contry': [],\n",
        "    'postalCode': [],\n",
        "    'resourceId': [],\n",
        "    'resource_name': [],\n",
        "    'resource_description': [],\n",
        "    'resource_active': [],\n",
        "    'resource_classifier': [],\n",
        "    'baseUnit': []\n",
        "}"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgDRuEP0izzJ"
      },
      "source": [
        "## Verification and loading of metadata for all available active resources\n",
        "for resource in all_resources:\n",
        "  if resource.get('status') == 'CONNECTED':\n",
        "    # print(resource.get('id'))\n",
        "    start_date = date_now - relativedelta(months=month_period)\n",
        "    verify = _session.query(Metadata).filter(Metadata.resourceId == resource.get('id')).first()\n",
        "    \n",
        "    if verify:\n",
        "      _session.execute(\n",
        "        update(\n",
        "          Metadata,\n",
        "          values= {\n",
        "            'veId':resource.get('site_id'),\n",
        "            've_name':resource.get('site_name'),\n",
        "            've_active':True if resource.get('status') == 'CONNECTED' else False,\n",
        "            've_city':resource.get('site_name'),\n",
        "            've_contry':resource.get('site_name'),\n",
        "            'postalCode':resource.get('sku'),\n",
        "            'resource_name':resource.get('name'),\n",
        "            'resource_description':resource.get('gateway_name'),\n",
        "            'resource_active':True if resource.get('status') == 'CONNECTED' else False,\n",
        "            'resource_classifier':resource.get('user_state'),\n",
        "            'baseUnit':\"Kwh\"\n",
        "          }\n",
        "          ).where(\n",
        "              Metadata.resourceId == resource.get('id')\n",
        "          )\n",
        "      )\n",
        "      _session.commit()\n",
        "    else:\n",
        "      metadata = Metadata(\n",
        "        veId=resource.get('site_id'),\n",
        "        ve_name=resource.get('site_name'),\n",
        "        ve_active=True if resource.get('status') == 'CONNECTED' else False,\n",
        "        ve_city=resource.get('site_name'),\n",
        "        ve_contry=resource.get('site_name'),\n",
        "        postalCode=resource.get('sku'),\n",
        "        resourceId=resource.get('id'),\n",
        "        resource_name=resource.get('name'),\n",
        "        resource_description=resource.get('gateway_name'),\n",
        "        resource_active=True if resource.get('status') == 'CONNECTED' else False,\n",
        "        resource_classifier=resource.get('user_state'),\n",
        "        baseUnit=\"Kwh\"\n",
        "        )\n",
        "      _session.add(metadata)\n",
        "      _session.commit()\n",
        "      print(F\"The resource data is saved in the metadata table: {resource.get('id')}, Date: {start_date}\")\n",
        "      for data in range(month_period):\n",
        "        reading = gd.get_readings(resource.get('id'), start_date, period_days, period)\n",
        "        values = process_readings_to_values(reading)\n",
        "        is_good_data = gd.is_data_good(values, False)\n",
        "          \n",
        "        if is_good_data:\n",
        "          for consumption in reading:\n",
        "            time_consumption = consumption[1]\n",
        "            consumption_value = consumption[2]\n",
        "            if consumption_value != 0 and consumption_value is not None:\n",
        "              verify = session.query(ConsumptionResources).filter(\n",
        "                  ConsumptionResources.timestamp == time_consumption,  ConsumptionResources.reference_resource == resource.get('id')\n",
        "              ).first()\n",
        "              if not verify:\n",
        "                consumptio_resources = ConsumptionResources(\n",
        "                    timestamp=time_consumption,\n",
        "                    consumption=consumption_value,\n",
        "                    reference_resource=resource.get('id')\n",
        "                )\n",
        "                _session.add(consumptio_resources)\n",
        "                _session.commit()\n",
        "                print(F\"The resource data is saved in the consumption table: {resource.get('id')}, Date: {time_consumption}\")\n",
        "              else:\n",
        "                print(F\"The consumption data already exists. Date exists: {time_consumption} and resource exists: {resource.get('id')}\")\n",
        "        start_date = start_date + relativedelta(months=1)\n",
        "        period_days = calendar.monthrange(start_date.year, start_date.month)[1] + 1\n",
        "  else:\n",
        "    print(F\"Resource not active >> : {resource.get('id')}\")\n",
        "    data_resources_inactive['veId'].append(resource.get('site_id'),)\n",
        "    data_resources_inactive['ve_name'].append(resource.get('site_name'),)\n",
        "    data_resources_inactive['ve_active'].append(True if resource.get('status') == 'CONNECTED' else False,)\n",
        "    data_resources_inactive['ve_city'].append(resource.get('site_name'),)\n",
        "    data_resources_inactive['ve_contry'].append(resource.get('site_name'),)\n",
        "    data_resources_inactive['postalCode'].append(resource.get('sku'),)\n",
        "    data_resources_inactive['resourceId'].append(resource.get('id'),)\n",
        "    data_resources_inactive['resource_name'].append(resource.get('name'),)\n",
        "    data_resources_inactive['resource_description'].append(resource.get('gateway_name'),)\n",
        "    data_resources_inactive['resource_active'].append(True if resource.get('status') == 'CONNECTED' else False,)\n",
        "    data_resources_inactive['resource_classifier'].append(resource.get('user_state'),)\n",
        "    data_resources_inactive['baseUnit'].append(\"Kwh\")\n",
        "    \n",
        "  \n",
        "_session.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}